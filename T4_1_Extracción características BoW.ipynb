{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de características *Bag of Words*\n",
    "\n",
    "Primero importamos todas las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "pd.options.display.max_colwidth = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un pequeño cuerpo de textos de ejemplo *(CORPUS)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['El cielo es azul y bonito',\n",
    "          'Me encanta el cielo azul, pero no el cielo plomizo',\n",
    "          'Bonito cielo hacía ese día',\n",
    "          'Hoy he desayunado huevos con jamón y tostadas',\n",
    "          'Juan odia las tostadas y los huevos con jamón',\n",
    "          'las tostadas de jamón están muy buenas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del texto\n",
    "Definimos una función simple de limpieza y normalización del texto y la aplicamos a nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "def normalizar_doc(doc):\n",
    "    '''Función que normaliza un texto cogiendo sólo\n",
    "    las palabras en minúsculas mayores de 3 caracteres'''\n",
    "    # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # filtramos stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if\n",
    "                       len(t.text)>3 and # cojemos las palabras q tienen más de 3 carácteres\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cielo azul bonito'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probamos la función\n",
    "normalizar_doc(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El cielo es azul y bonito'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo azul bonito',\n",
       " 'encanta cielo azul pero cielo plomizo',\n",
       " 'bonito cielo hacía',\n",
       " 'desayunado huevos jamón tostadas',\n",
       " 'juan odia tostadas huevos jamón',\n",
       " 'tostadas jamón están buenas']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aplicamos a todo el corpus\n",
    "norm_corpus = [normalizar_doc(doc) for doc in corpus]\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo azul bonito',\n",
       " 'encanta cielo azul pero cielo plomizo',\n",
       " 'bonito cielo hacía',\n",
       " 'desayunado huevos jamón tostadas',\n",
       " 'juan odia tostadas huevos jamón',\n",
       " 'tostadas jamón están buenas']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternativamente\n",
    "list(map(normalizar_doc, corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería `scikit-learn`\n",
    "Implementamos el modelo Bag-of-Word (BoW) con `scikit-learn`\n",
    "\n",
    "Contamos la frecuencia de aparición de los términos en cada documento, usando un vocabulario común. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(norm_corpus) #también funcionaría cv.fit(map(normalizar_doc, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azul',\n",
       " 'bonito',\n",
       " 'buenas',\n",
       " 'cielo',\n",
       " 'desayunado',\n",
       " 'encanta',\n",
       " 'están',\n",
       " 'hacía',\n",
       " 'huevos',\n",
       " 'jamón',\n",
       " 'juan',\n",
       " 'odia',\n",
       " 'pero',\n",
       " 'plomizo',\n",
       " 'tostadas']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_matrix = cv.transform(norm_corpus)\n",
    "cv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matriz sparse\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 13)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 9)\t1\n",
      "  (3, 14)\t1\n",
      "  (4, 8)\t1\n",
      "  (4, 9)\t1\n",
      "  (4, 10)\t1\n",
      "  (4, 11)\t1\n",
      "  (4, 14)\t1\n",
      "  (5, 2)\t1\n",
      "  (5, 6)\t1\n",
      "  (5, 9)\t1\n",
      "  (5, 14)\t1\n"
     ]
    }
   ],
   "source": [
    "#sólo guarda info de las celdas no vacías\n",
    "print(cv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada término único es una característica de la matriz generada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul</th>\n",
       "      <th>bonito</th>\n",
       "      <th>buenas</th>\n",
       "      <th>cielo</th>\n",
       "      <th>desayunado</th>\n",
       "      <th>encanta</th>\n",
       "      <th>están</th>\n",
       "      <th>hacía</th>\n",
       "      <th>huevos</th>\n",
       "      <th>jamón</th>\n",
       "      <th>juan</th>\n",
       "      <th>odia</th>\n",
       "      <th>pero</th>\n",
       "      <th>plomizo</th>\n",
       "      <th>tostadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul  bonito  buenas  cielo  desayunado  encanta  están  hacía  huevos  \\\n",
       "0     1       1       0      1           0        0      0      0       0   \n",
       "1     1       0       0      2           0        1      0      0       0   \n",
       "2     0       1       0      1           0        0      0      1       0   \n",
       "3     0       0       0      0           1        0      0      0       1   \n",
       "4     0       0       0      0           0        0      0      0       1   \n",
       "5     0       0       1      0           0        0      1      0       0   \n",
       "\n",
       "   jamón  juan  odia  pero  plomizo  tostadas  \n",
       "0      0     0     0     0        0         0  \n",
       "1      0     0     0     1        1         0  \n",
       "2      0     0     0     0        0         0  \n",
       "3      1     0     0     0        0         1  \n",
       "4      1     1     1     0        0         1  \n",
       "5      1     0     0     0        0         1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtenemos palabras únicas en el corpus\n",
    "vocab = cv.get_feature_names()\n",
    "# mostramos vectores de características BoW del corpus\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo genera un diccionario con todas las palabras del vocabulario y asigna un índice único a cada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cielo': 3,\n",
       " 'azul': 0,\n",
       " 'bonito': 1,\n",
       " 'encanta': 5,\n",
       " 'pero': 12,\n",
       " 'plomizo': 13,\n",
       " 'hacía': 7,\n",
       " 'desayunado': 4,\n",
       " 'huevos': 8,\n",
       " 'jamón': 9,\n",
       " 'tostadas': 14,\n",
       " 'juan': 10,\n",
       " 'odia': 11,\n",
       " 'están': 6,\n",
       " 'buenas': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#id de las palabras del vocabulario\n",
    "cv.vocabulary_.get('cielo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si una palabra no está en el vocabulario...\n",
    "cv.vocabulary_.get('lluvia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando el modelo a nuevos documentos\n",
    "Cuando calculamos el vector BoW de un texto nuevo con el modelo no hay que volver a ajustar el vocabulario, por lo que los términos nuevos no se tendrán en cuenta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevo_corpus = ['El Cielo amenaza lluvia', 'Pedro desayuna tostadas de jamón con tomate']\n",
    "cv_matrix_nueva = cv.transform(map(normalizar_doc, nuevo_corpus))\n",
    "cv_matrix_nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul</th>\n",
       "      <th>bonito</th>\n",
       "      <th>buenas</th>\n",
       "      <th>cielo</th>\n",
       "      <th>desayunado</th>\n",
       "      <th>encanta</th>\n",
       "      <th>están</th>\n",
       "      <th>hacía</th>\n",
       "      <th>huevos</th>\n",
       "      <th>jamón</th>\n",
       "      <th>juan</th>\n",
       "      <th>odia</th>\n",
       "      <th>pero</th>\n",
       "      <th>plomizo</th>\n",
       "      <th>tostadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul  bonito  buenas  cielo  desayunado  encanta  están  hacía  huevos  \\\n",
       "0     0       0       0      1           0        0      0      0       0   \n",
       "1     0       0       0      0           0        0      0      0       0   \n",
       "\n",
       "   jamón  juan  odia  pero  plomizo  tostadas  \n",
       "0      0     0     0     0        0         0  \n",
       "1      1     0     0     0        0         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_matrix_nueva.toarray(), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos N-grams\n",
    "Considera como términos del vocabulario cada secuencia de N palabras consecutivas que aparece en el texto (*n-gramas*).  \n",
    "Por ejemplo para los *bigrams* del corpus (N=2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azul bonito',\n",
       " 'azul pero',\n",
       " 'bonito cielo',\n",
       " 'cielo azul',\n",
       " 'cielo hacía',\n",
       " 'cielo plomizo',\n",
       " 'desayunado huevos',\n",
       " 'encanta cielo',\n",
       " 'están buenas',\n",
       " 'huevos jamón',\n",
       " 'jamón están',\n",
       " 'jamón tostadas',\n",
       " 'juan odia',\n",
       " 'odia tostadas',\n",
       " 'pero cielo',\n",
       " 'tostadas huevos',\n",
       " 'tostadas jamón']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x17 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul bonito</th>\n",
       "      <th>azul pero</th>\n",
       "      <th>bonito cielo</th>\n",
       "      <th>cielo azul</th>\n",
       "      <th>cielo hacía</th>\n",
       "      <th>cielo plomizo</th>\n",
       "      <th>desayunado huevos</th>\n",
       "      <th>encanta cielo</th>\n",
       "      <th>están buenas</th>\n",
       "      <th>huevos jamón</th>\n",
       "      <th>jamón están</th>\n",
       "      <th>jamón tostadas</th>\n",
       "      <th>juan odia</th>\n",
       "      <th>odia tostadas</th>\n",
       "      <th>pero cielo</th>\n",
       "      <th>tostadas huevos</th>\n",
       "      <th>tostadas jamón</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul bonito  azul pero  bonito cielo  cielo azul  cielo hacía  \\\n",
       "0            1          0             0           1            0   \n",
       "1            0          1             0           1            0   \n",
       "2            0          0             1           0            1   \n",
       "3            0          0             0           0            0   \n",
       "4            0          0             0           0            0   \n",
       "5            0          0             0           0            0   \n",
       "\n",
       "   cielo plomizo  desayunado huevos  encanta cielo  están buenas  \\\n",
       "0              0                  0              0             0   \n",
       "1              1                  0              1             0   \n",
       "2              0                  0              0             0   \n",
       "3              0                  1              0             0   \n",
       "4              0                  0              0             0   \n",
       "5              0                  0              0             1   \n",
       "\n",
       "   huevos jamón  jamón están  jamón tostadas  juan odia  odia tostadas  \\\n",
       "0             0            0               0          0              0   \n",
       "1             0            0               0          0              0   \n",
       "2             0            0               0          0              0   \n",
       "3             1            0               1          0              0   \n",
       "4             1            0               0          1              1   \n",
       "5             0            1               0          0              0   \n",
       "\n",
       "   pero cielo  tostadas huevos  tostadas jamón  \n",
       "0           0                0               0  \n",
       "1           1                0               0  \n",
       "2           0                0               0  \n",
       "3           0                0               0  \n",
       "4           0                1               0  \n",
       "5           0                0               1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab_bigram = bv.get_feature_names()\n",
    "pd.DataFrame(bv_matrix, columns=vocab_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azul bonito',\n",
       " 'azul pero',\n",
       " 'bonito cielo',\n",
       " 'cielo azul',\n",
       " 'cielo hacía',\n",
       " 'cielo plomizo',\n",
       " 'desayunado huevos',\n",
       " 'encanta cielo',\n",
       " 'están buenas',\n",
       " 'huevos jamón',\n",
       " 'jamón están',\n",
       " 'jamón tostadas',\n",
       " 'juan odia',\n",
       " 'odia tostadas',\n",
       " 'pero cielo',\n",
       " 'tostadas huevos',\n",
       " 'tostadas jamón']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede establecer el rango de n-grams a `(1,2)` para obtener el conjunto de unigramas y bigramas del corpus.  \n",
    "Para limitar el número de términos en el vocabulario del modelo BoW se puede limitar a los términos que aparecen en un mínimo de documentos con el parámetro `min_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul</th>\n",
       "      <th>bonito</th>\n",
       "      <th>cielo</th>\n",
       "      <th>cielo azul</th>\n",
       "      <th>huevos</th>\n",
       "      <th>huevos jamón</th>\n",
       "      <th>jamón</th>\n",
       "      <th>tostadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul  bonito  cielo  cielo azul  huevos  huevos jamón  jamón  tostadas\n",
       "0     1       1      1           1       0             0      0         0\n",
       "1     1       0      2           1       0             0      0         0\n",
       "2     0       1      1           0       0             0      0         0\n",
       "3     0       0      0           0       1             1      1         1\n",
       "4     0       0      0           0       1             1      1         1\n",
       "5     0       0      0           0       0             0      1         1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv = CountVectorizer(ngram_range=(1,2), min_df=2)\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab_bigram = bv.get_feature_names()\n",
    "pd.DataFrame(bv_matrix, columns=vocab_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azul',\n",
       " 'bonito',\n",
       " 'cielo',\n",
       " 'cielo azul',\n",
       " 'huevos',\n",
       " 'huevos jamón',\n",
       " 'jamón',\n",
       " 'tostadas']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería `Gensim`\n",
    "Para trabajar con la librería `Gensim` es necesario transformar los documentos en una lista de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(text):\n",
    "    return [token.text for token in nlp.make_doc(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos nuestros texto de ejemplo en una lista de tokens y visualizamos el primer documento como ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['El', 'cielo', 'es', 'azul', 'y', 'bonito'],\n",
       " ['Me',\n",
       "  'encanta',\n",
       "  'el',\n",
       "  'cielo',\n",
       "  'azul',\n",
       "  ',',\n",
       "  'pero',\n",
       "  'no',\n",
       "  'el',\n",
       "  'cielo',\n",
       "  'plomizo'],\n",
       " ['Bonito', 'cielo', 'hacía', 'ese', 'día'],\n",
       " ['Hoy', 'he', 'desayunado', 'huevos', 'con', 'jamón', 'y', 'tostadas'],\n",
       " ['Juan', 'odia', 'las', 'tostadas', 'y', 'los', 'huevos', 'con', 'jamón'],\n",
       " ['las', 'tostadas', 'de', 'jamón', 'están', 'muy', 'buenas']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus = [word_tokenize(doc) for doc in corpus]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_doc_tokenize(doc):\n",
    "    '''Función que normaliza un texto cogiendo sólo\n",
    "    las palabras en minúsculas mayores de 3 caracteres'''\n",
    "    # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # filtramos stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if\n",
    "                       len(t.text)>3 and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo', 'azul', 'bonito']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizar_doc_tokenize(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cielo', 'azul', 'bonito'],\n",
       " ['encanta', 'cielo', 'azul', 'pero', 'cielo', 'plomizo'],\n",
       " ['bonito', 'cielo', 'hacía'],\n",
       " ['desayunado', 'huevos', 'jamón', 'tostadas'],\n",
       " ['juan', 'odia', 'tostadas', 'huevos', 'jamón'],\n",
       " ['tostadas', 'jamón', 'están', 'buenas']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus = [normalizar_doc_tokenize(doc) for doc in corpus]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Bag of Words\n",
    "Se pasará al modelo de Gensim como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "diccionario = Dictionary(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7fe653e0dac0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ID de cada palabra del diccionario se obtiene con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'azul': 0,\n",
       " 'bonito': 1,\n",
       " 'cielo': 2,\n",
       " 'encanta': 3,\n",
       " 'pero': 4,\n",
       " 'plomizo': 5,\n",
       " 'hacía': 6,\n",
       " 'desayunado': 7,\n",
       " 'huevos': 8,\n",
       " 'jamón': 9,\n",
       " 'tostadas': 10,\n",
       " 'juan': 11,\n",
       " 'odia': 12,\n",
       " 'buenas': 13,\n",
       " 'están': 14}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería `gensim` crea la matriz BoW con otro formato. A cada palabra distinta del corpus se le asigna un ID único. Por cada documento se genera una lista de tuplas (ID, frecuencia) con la frecuencia de aparición de cada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.doc2bow(tokenized_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.token2id['plomizo'] #ID de cada término"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plomizo'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario[5] #término correspondiente a una ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'azul',\n",
       " 1: 'bonito',\n",
       " 2: 'cielo',\n",
       " 3: 'encanta',\n",
       " 4: 'pero',\n",
       " 5: 'plomizo',\n",
       " 6: 'hacía',\n",
       " 7: 'desayunado',\n",
       " 8: 'huevos',\n",
       " 9: 'jamón',\n",
       " 10: 'tostadas',\n",
       " 11: 'juan',\n",
       " 12: 'odia',\n",
       " 13: 'buenas',\n",
       " 14: 'están'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.id2token #diccionario de palabras para cada ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_corpus = [diccionario.doc2bow(text)\n",
    "                 for text in tokenized_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (2, 2), (3, 1), (4, 1), (5, 1)],\n",
       " [(1, 1), (2, 1), (6, 1)],\n",
       " [(7, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(9, 1), (10, 1), (13, 1), (14, 1)]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azul: 1\n",
      "cielo: 2\n",
      "encanta: 1\n",
      "pero: 1\n",
      "plomizo: 1\n"
     ]
    }
   ],
   "source": [
    "for (i, tf) in mapped_corpus[1]:\n",
    "    print(f\"{diccionario[i]}: {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 3,\n",
       " 0: 2,\n",
       " 1: 2,\n",
       " 3: 1,\n",
       " 4: 1,\n",
       " 5: 1,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 2,\n",
       " 9: 3,\n",
       " 10: 3,\n",
       " 11: 1,\n",
       " 12: 1,\n",
       " 14: 1,\n",
       " 13: 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frec. de documentos de cada token\n",
    "diccionario.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cielo: 3\n",
      "azul: 2\n",
      "bonito: 2\n",
      "encanta: 1\n",
      "pero: 1\n",
      "plomizo: 1\n",
      "hacía: 1\n",
      "desayunado: 1\n",
      "huevos: 2\n",
      "jamón: 3\n",
      "tostadas: 3\n",
      "juan: 1\n",
      "odia: 1\n",
      "están: 1\n",
      "buenas: 1\n"
     ]
    }
   ],
   "source": [
    "for i in diccionario.dfs:\n",
    "    print(f\"{diccionario[i]}: {diccionario.dfs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 4,\n",
       " 0: 2,\n",
       " 1: 2,\n",
       " 3: 1,\n",
       " 4: 1,\n",
       " 5: 1,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 2,\n",
       " 9: 3,\n",
       " 10: 3,\n",
       " 11: 1,\n",
       " 12: 1,\n",
       " 14: 1,\n",
       " 13: 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frec. aparición total de cada token\n",
    "diccionario.cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cielo: 4\n",
      "azul: 2\n",
      "bonito: 2\n",
      "encanta: 1\n",
      "pero: 1\n",
      "plomizo: 1\n",
      "hacía: 1\n",
      "desayunado: 1\n",
      "huevos: 2\n",
      "jamón: 3\n",
      "tostadas: 3\n",
      "juan: 1\n",
      "odia: 1\n",
      "están: 1\n",
      "buenas: 1\n"
     ]
    }
   ],
   "source": [
    "for i in diccionario.cfs:\n",
    "    print(f\"{diccionario[i]}: {diccionario.cfs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de los modelos a nuevos textos\n",
    "Para aplicar un modelo BoW o TF-IDF a un nuevo documento hay que utilizar los modelos ya entrenados en `gensim` sobre el corpus original\n",
    "### Modelo BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1)], [(9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_nuevo_corpus = [normalizar_doc_tokenize(doc) for doc in nuevo_corpus]\n",
    "\n",
    "mapped_nuevo_corpus = [diccionario.doc2bow(text)\n",
    "                 for text in tokenized_nuevo_corpus]\n",
    "\n",
    "mapped_nuevo_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cielo', 'amenaza', 'lluvia'],\n",
       " ['pedro', 'desayuna', 'tostadas', 'jamón', 'tomate']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_nuevo_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jamón: 1\n",
      "tostadas: 1\n"
     ]
    }
   ],
   "source": [
    "for (i, tf) in mapped_nuevo_corpus[1]:\n",
    "    print(f\"{diccionario[i]}: {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1)], [(9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Más pythonico con 'map'\n",
    "list(map(diccionario.doc2bow, map(normalizar_doc_tokenize, nuevo_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1)], [(9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#o mejor incluso\n",
    "list(map(lambda x: diccionario.doc2bow(normalizar_doc_tokenize(x)), nuevo_corpus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
